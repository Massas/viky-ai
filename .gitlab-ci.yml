stages:
  - prerequist
  - build
  - test
  - docker_tag
  - deploy
  - admin

image: registry.gitlab.com/brice.ruzand/auto-deploy-image/master:a4aec2bfb7d168e93cdb8548c8d7a39c39adae05

.kubernetes_runner:
  tags:
    - kubernetes

variables:
  SKIP_TEST: "true"
  CI_SERVICE_HOST: "127.0.0.1"
  GIT_SUBMODULE_STRATEGY: none
  DOCKER_HOST: "tcp://dood:2375"
  DOCKER_DRIVER: overlay2
  DOCKER_IMAGE_APP: $CI_REGISTRY_IMAGE/app
  DOCKER_IMAGE_NLP: $CI_REGISTRY_IMAGE/nlp
  DOCKER_IMAGE_TOOLS_NLP: $CI_REGISTRY_IMAGE/tools_nlp_base
  DOCKER_IMAGE_TOOLS_RUBY: $CI_REGISTRY_IMAGE/tools_ruby_base
  DOCKER_IMAGE_TOOLS_BACKUP: $CI_REGISTRY_IMAGE/tools_backup

# Build docker image

build_ruby_base:
  extends: .kubernetes_runner
  stage: prerequist
  script:
    - docker_build ${DOCKER_IMAGE_TOOLS_RUBY}      deployment/docker_tools/ruby_base "--target image_ruby_base"
    - docker_build ${DOCKER_IMAGE_TOOLS_RUBY}_test deployment/docker_tools/ruby_base "--target image_ruby_base_test"

build_nlp_base:
  extends: .kubernetes_runner
  stage: prerequist
  script:
    - docker_build ${DOCKER_IMAGE_TOOLS_NLP} nlp/tools/docker

build_backup:
  extends: .kubernetes_runner
  stage: prerequist
  script:
    - docker_build ${DOCKER_IMAGE_TOOLS_BACKUP} deployment/docker_tools/backup "--build-arg VIKYAPP_BACKUP_PASSWORD=${VIKYAPP_BACKUP_PASSWORD}"

elastic_keystore:
  extends: .kubernetes_runner
  stage: prerequist
  script:
    - cd deployment/kubernetes/
    - bin/generateS3Keystore.sh ./viky-platform/custom-values/
  artifacts:
    paths:
      - deployment/kubernetes/viky-platform/custom-values/elasticsearch.keystore
    # expire_in: 1 hour

build_webapp:
  extends: .kubernetes_runner
  needs: ["build_ruby_base"]
  stage: build
  script:
    - docker_build ${DOCKER_IMAGE_APP}      webapp "--build-arg VIKY_IMAGE_TAG=${CI_COMMIT_REF_SLUG} --target image_ruby_run"

build_webapp_test:
  extends: .kubernetes_runner
  needs: ["build_ruby_base"]
  stage: build
  script:
    - docker_build ${DOCKER_IMAGE_APP}_test webapp "--build-arg VIKY_IMAGE_TAG=${CI_COMMIT_REF_SLUG} --target image_ruby_test"

build_nlp:
  extends: .kubernetes_runner
  stage: build
  needs: ["build_nlp_base"]
  variables:
    GIT_SUBMODULE_STRATEGY: recursive
  script:
    - docker_build ${DOCKER_IMAGE_NLP}      nlp "--build-arg VIKY_IMAGE_TAG=${CI_COMMIT_REF_SLUG} --target run_image"
    - docker_build ${DOCKER_IMAGE_NLP}_test nlp "--build-arg VIKY_IMAGE_TAG=${CI_COMMIT_REF_SLUG} --target test_image"

# Test
.test_webapp:
  extends: .kubernetes_runner
  stage: test
  image: ${DOCKER_IMAGE_APP}_test:${CI_COMMIT_REF_SLUG}
  needs: ["build_webapp_test"]
  variables:
    POSTGRES_USER: superman
    POSTGRES_PASSWORD: sup_3rman
    POSTGRES_DB: vikyapp_test
  services:
    - postgres:11.5-alpine
    - redis:5.0-alpine
    - name: docker.elastic.co/elasticsearch/elasticsearch:7.3.2
      # Important other wise, port 9200 will never be exposed
      command:
        [
          "bin/elasticsearch",
          "-Ediscovery.type=single-node",
          "-Enetwork.host=0.0.0.0",
        ]
      alias: elasticsearch
  before_script:
    - export VIKYAPP_DB_USERNAME="${POSTGRES_USER}"
    - export VIKYAPP_DB_PASSWORD="${POSTGRES_PASSWORD}"
    - export VIKYAPP_DB_HOST="${CI_SERVICE_HOST:-postgres}"
    - export VIKYAPP_ACTIONCABLE_REDIS_URL="redis://${CI_SERVICE_HOST:-redis}:6379/1"
    - export VIKYAPP_ACTIVEJOB_REDIS_URL="redis://${CI_SERVICE_HOST:-redis}:6379/2"
    - export VIKYAPP_STATISTICS_URL="http://${CI_SERVICE_HOST:-elasticsearch}:9200"
    - export VIKYAPP_STATISTICS_NO_REPLICA="true"
    - cd /webapp
  artifacts:
    # expire_in: 1 week
    reports:
      junit: "reports/TEST-*.xml"

test_webapp_unit:
  extends: .test_webapp
  script:
    - cd /webapp
    - if [ "${SKIP_TEST:-false}" != "true" ]; then ./bin/docker_run_test.sh unit ; fi

# Test
test_webapp_system:
  extends: .test_webapp
  script:
    - if [ "${SKIP_TEST:-false}" != "true" ]; then ./bin/docker_run_test.sh system ; fi

test_nlp:
  extends: .kubernetes_runner
  stage: test
  needs: ["build_nlp"]
  image: ${DOCKER_IMAGE_NLP}_test:${CI_COMMIT_REF_SLUG}
  services:
    - redis:5.0-alpine
  variables:
    GIT_STRATEGY: none
  script:
    - export VIKYAPP_REDIS_PACKAGE_NOTIFIER="redis://${CI_SERVICE_HOST:-redis}:6379/3"
    - if [ "${SKIP_TEST:-false}" != "true" ]; then /docker_run_test.sh ; fi
  artifacts:
    # expire_in: 1 week
    reports:
      junit:
        - "reports/TEST-*.xml"

# Tag docker image to lasted
tag_webapp:
  extends: .kubernetes_runner
  stage: docker_tag
  only:
    - develop
  variables:
    GIT_STRATEGY: none
  script:
    - docker_tag_latest ${DOCKER_IMAGE_APP}
    - docker_tag_latest ${DOCKER_IMAGE_APP}_test

tag_nlp:
  extends: .kubernetes_runner
  stage: docker_tag
  needs: ["build_nlp", "test_nlp"]
  only:
    - develop
  variables:
    GIT_STRATEGY: none
  script:
    - docker_tag_latest ${DOCKER_IMAGE_NLP}

tag_ruby_base:
  extends: .kubernetes_runner
  stage: docker_tag
  only:
    - develop
  variables:
    GIT_STRATEGY: none
  script:
    - docker_tag_latest ${DOCKER_IMAGE_TOOLS_RUBY}
    - docker_tag_latest ${DOCKER_IMAGE_TOOLS_RUBY}_test

tag_backup:
  extends: .kubernetes_runner
  stage: docker_tag
  only:
    - develop
  variables:
    GIT_STRATEGY: none
  script:
    - docker_tag_latest ${DOCKER_IMAGE_TOOLS_BACKUP}

# Deploy any branches on dev
deploy_dev:
  extends: .kubernetes_runner
  stage: deploy
  except:
    - master
    - tags
  dependencies:
    - elastic_keystore
    - build_webapp
    - build_nlp
  environment:
    name: ${CI_COMMIT_REF_NAME}
    url: https://viky-${CI_ENVIRONMENT_SLUG}-kube.viky.ai
    on_stop: delete_env
  variables:
    VIKY_IMAGE_TAG: ${CI_COMMIT_REF_SLUG}
    S3_ACCESS_KEY: ${S3_ACCESS_KEY}
    S3_SECRET_KEY: ${S3_SECRET_KEY}
  script:
    # gitlab auto autodeploy setup
    # TODO customize generic part in docker image
    - auto-deploy ensure_namespace
    - export TILLER_NAMESPACE=${KUBE_NAMESPACE}
    - export SERVICE_ACCOUNT="${KUBE_NAMESPACE}-service-account"
    - auto-deploy create_secret
    - setup_release_name
    - unset HELM_HOST
    - helm init --upgrade --wait --history-max=5 --tiller-connection-timeout=30 --service-account ${SERVICE_ACCOUNT} --tiller-namespace "${KUBE_NAMESPACE}"
    - helm history "${RELEASE_NAME}" || true
    - helm status  "${RELEASE_NAME}" || true
    # Go to Kubernetes directory
    - cd deployment/kubernetes/
    - echo "Generate Override values"
    - bin/generateOverrideValuesFile.sh
    # Deploy Viky Platform
    - unset HELM_HOST
    - helm upgrade --wait --timeout 600 --install --namespace "${KUBE_NAMESPACE}" --values custom-values.yml,viky-platform/custom-values/production.yaml "${RELEASE_NAME}"  ./viky-platform/
# Deploy master on preprod
deploy_preprod:
  extends: .kubernetes_runner
  stage: deploy
  only:
    - master
  except:
    - tags
  dependencies:
    - elastic_keystore
    - build_webapp
    - build_nlp
  environment:
    name: viky-preprod
    url: https://viky-beta-kube.viky.ai
  variables:
    VIKYAPP_AUTO_BACKUP: "true"
    VIKY_IMAGE_TAG: ${CI_COMMIT_REF_SLUG}
    S3_ACCESS_KEY: ${S3_ACCESS_KEY}
    S3_SECRET_KEY: ${S3_SECRET_KEY}
  script:
    # TODO
    - "false"

# remove environment
delete_env:
  extends: .kubernetes_runner
  stage: admin
  except:
    - master
    - tags
  environment:
    name: ${CI_COMMIT_REF_NAME}
    url: https://viky-${CI_ENVIRONMENT_SLUG}-kube.viky.ai
    action: stop
  script:
    - auto-deploy ensure_namespace
    - export TILLER_NAMESPACE=${KUBE_NAMESPACE}
    - export SERVICE_ACCOUNT="${KUBE_NAMESPACE}-service-account"
    - auto-deploy create_secret
    - setup_release_name
    - unset HELM_HOST
    - helm init --upgrade --wait --history-max=5 --tiller-connection-timeout=30 --service-account ${SERVICE_ACCOUNT} --tiller-namespace "${KUBE_NAMESPACE}"
    - helm history "${RELEASE_NAME}" || true
    - helm status  "${RELEASE_NAME}" || true
    - helm delete --purge --no-hooks "${RELEASE_NAME}"
    - kubectl delete all,cm,pvc,ev,pdb --all --namespace "${KUBE_NAMESPACE}"
  when: manual
  allow_failure: true

# invite admin user
invite_admin_dev:
  extends: .kubernetes_runner
  stage: admin
  except:
    - master
    - tags
  environment:
    name: ${CI_COMMIT_REF_NAME}
    url: https://viky-${CI_ENVIRONMENT_SLUG}-kube.viky.ai
  variables:
    GIT_STRATEGY: none
  script:
    - PODNAME=$(get_pods "app=viky-webapp")
    - kubectl --namespace=${KUBE_NAMESPACE} exec $PODNAME ./bin/rails users:invite_admin[${GITLAB_USER_EMAIL}]
  when: manual
  allow_failure: true

# invite admin user
invite_admin_preprod:
  extends: .kubernetes_runner
  stage: admin
  only:
    - master
  environment:
    name: viky-preprod
    url: https://viky-beta-kube.viky.ai
  variables:
    GIT_STRATEGY: none
  script:
    - PODNAME=$(get_pods "app=viky-webapp")
    - kubectl --namespace=${KUBE_NAMESPACE} exec $PODNAME ./bin/rails users:invite_admin[${GITLAB_USER_EMAIL}]
  when: manual
  allow_failure: true

# backup
backup_dev:
  extends: .kubernetes_runner
  stage: admin
  dependencies: []
  except:
    - master
    - tags
  environment:
    name: ${CI_COMMIT_REF_NAME}
    url: https://viky-${CI_ENVIRONMENT_SLUG}-kube.viky.ai
  variables:
    GIT_STRATEGY: none
  script:
    - PODNAME=$(get_pods "app=viky-webapp-backup")
    - kubectl exec --namespace=${KUBE_NAMESPACE} ${PODNAME}  bash /backup/backup.sh
  when: manual
  allow_failure: true

# backup
backup_preprod:
  extends: .kubernetes_runner
  stage: admin
  dependencies: []
  only:
    - master
  environment:
    name: viky-preprod
    url: https://viky-beta-kube.viky.ai
  variables:
    GIT_STRATEGY: none
  script:
    - PODNAME=$(get_pods "app=viky-webapp-backup")
    - kubectl exec --namespace=${KUBE_NAMESPACE} ${PODNAME}  bash /backup/backup.sh
  when: manual
  allow_failure: true

# backup restore
backup_restore_dev:
  extends: .kubernetes_runner
  stage: admin
  dependencies: []
  except:
    - master
    - tags
  environment:
    name: ${CI_COMMIT_REF_NAME}
    url: https://viky-${CI_ENVIRONMENT_SLUG}-kube.viky.ai
  variables:
    GIT_STRATEGY: none
  script:
    - PODNAME=$(get_pods "app=viky-webapp-backup")
    # backup current env
    - kubectl exec --namespace=${KUBE_NAMESPACE} $PODNAME  bash /backup/backup.sh || true
    # restore base on viky-beta
    - kubectl exec --namespace=${KUBE_NAMESPACE} $PODNAME  bash /backup/restore.sh "viky-beta"
    # delete pods to restart wiky apps deployment
    - kubectl delete pods --namespace=${KUBE_NAMESPACE} -l 'app in (viky-webapp-worker, viky-webapp, viky-nlp)'
  when: manual
  allow_failure: true

before_script:
  - |
    # Auto DevOps variables and functions
    [[ "${TRACE:-0}" == "1" ]] && set -x

    # Needed for Gitlab Managed
    export TILLER_NAMESPACE="${KUBE_NAMESPACE}"
    export HELM_HOST="localhost:44134"

    function docker_build ()
    {
      # login to private registry
      docker_login

      local CI_DOCKER_IMAGE="$1"
      local CI_DOCKER_DIR="$2"
      local CI_DOCKER_IMAGE_BUILD_OPT="$3"

      echo ""
      echo "Build docker image ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG} from dir ${CI_DOCKER_DIR} ..."
      docker build --pull ${CI_DOCKER_IMAGE_BUILD_OPT} -t ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG} ${CI_DOCKER_DIR}

      echo ""
      echo "Pushing ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG} to GitLab Container Registry ..."
      docker push ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG}

      echo ""
    }

    function docker_tag_latest ()
    {
      # login to private registry
      docker_login

      local CI_DOCKER_IMAGE="$1"

      echo "Pulling ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG}"
      docker pull ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG}

      echo "Taggging ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG} to ${CI_DOCKER_IMAGE}:latest"
      docker tag ${CI_DOCKER_IMAGE}:${CI_COMMIT_REF_SLUG} ${CI_DOCKER_IMAGE}:latest

      echo "Pushing ${CI_DOCKER_IMAGE}:latest to GitLab Container Registry ..."
      docker push ${CI_DOCKER_IMAGE}:latest
      echo ""
    }

    function docker_login ()
    {
      if [[ -n "$CI_REGISTRY_USER" ]]; then
        echo "Logging to GitLab Container Registry with CI credentials ..."
        echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
        echo ""
      fi
    }

    function setup_release_name ()
    {
      export RELEASE_NAME=viky-$(echo "${KUBE_NAMESPACE}" | sha1sum | awk '{print $1}' | cut -c -10)
    }

    function get_pods ()
    {
      local KUBE_SELECTOR="$1"
      kubectl get pods --namespace="${KUBE_NAMESPACE}" -l "${KUBE_SELECTOR}" --no-headers --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}'
    }
